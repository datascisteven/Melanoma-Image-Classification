{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "6555959b910bb7a8fb6f47a2dcc8365b919d4ffbc6f566ad680344e31443b77e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importing Packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "from skimage.color import label2rgb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           file  patient_id   lesion_id  gender   age             site  \\\n",
       "0  ISIC_2637011  IP_7279968  IL_7972535    male  45.0        head/neck   \n",
       "1  ISIC_0015719  IP_3075186  IL_4649854  female  45.0  upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  IL_9087444  female  50.0  lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  IL_4255399  female  45.0        head/neck   \n",
       "4  ISIC_0074268  IP_8723313  IL_6898037  female  55.0  upper extremity   \n",
       "\n",
       "  diagnosis ben_mal  target  gen_enc  site_enc  diag_enc  \n",
       "0   unknown  benign       0        1         0         8  \n",
       "1   unknown  benign       0        0         6         8  \n",
       "2     nevus  benign       0        0         1         5  \n",
       "3   unknown  benign       0        0         0         8  \n",
       "4   unknown  benign       0        0         6         8  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>patient_id</th>\n      <th>lesion_id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>site</th>\n      <th>diagnosis</th>\n      <th>ben_mal</th>\n      <th>target</th>\n      <th>gen_enc</th>\n      <th>site_enc</th>\n      <th>diag_enc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>IL_7972535</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>IL_4649854</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>IL_9087444</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>IL_4255399</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>IL_6898037</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "# Assigning Paths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DICOM ===\n",
    "# Create the paths\n",
    "path_tr_dcm = '../split/train_dcm/' + df['file'] + '.dcm'\n",
    "path_tr_jpg = '../split/train/mel/2020/' + df['file'] + '.jpg'\n",
    "\n",
    "# Append to the original dataframes\n",
    "df['path_dcm'] = path_tr_dcm\n",
    "df['path_jpg'] = path_tr_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dcm'] = df.file.apply(lambda x: str(x) + '.dcm')\n",
    "df['jpg'] = df.file.apply(lambda x: str(x) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           file  patient_id   lesion_id  gender   age             site  \\\n",
       "0  ISIC_2637011  IP_7279968  IL_7972535    male  45.0        head/neck   \n",
       "1  ISIC_0015719  IP_3075186  IL_4649854  female  45.0  upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  IL_9087444  female  50.0  lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  IL_4255399  female  45.0        head/neck   \n",
       "4  ISIC_0074268  IP_8723313  IL_6898037  female  55.0  upper extremity   \n",
       "\n",
       "  diagnosis ben_mal  target  gen_enc  site_enc  diag_enc  \\\n",
       "0   unknown  benign       0        1         0         8   \n",
       "1   unknown  benign       0        0         6         8   \n",
       "2     nevus  benign       0        0         1         5   \n",
       "3   unknown  benign       0        0         0         8   \n",
       "4   unknown  benign       0        0         6         8   \n",
       "\n",
       "                              path_dcm  \\\n",
       "0  ../split/train_dcm/ISIC_2637011.dcm   \n",
       "1  ../split/train_dcm/ISIC_0015719.dcm   \n",
       "2  ../split/train_dcm/ISIC_0052212.dcm   \n",
       "3  ../split/train_dcm/ISIC_0068279.dcm   \n",
       "4  ../split/train_dcm/ISIC_0074268.dcm   \n",
       "\n",
       "                                   path_jpg  \n",
       "0  ../split/train/mel/2020/ISIC_2637011.jpg  \n",
       "1  ../split/train/mel/2020/ISIC_0015719.jpg  \n",
       "2  ../split/train/mel/2020/ISIC_0052212.jpg  \n",
       "3  ../split/train/mel/2020/ISIC_0068279.jpg  \n",
       "4  ../split/train/mel/2020/ISIC_0074268.jpg  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>patient_id</th>\n      <th>lesion_id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>site</th>\n      <th>diagnosis</th>\n      <th>ben_mal</th>\n      <th>target</th>\n      <th>gen_enc</th>\n      <th>site_enc</th>\n      <th>diag_enc</th>\n      <th>path_dcm</th>\n      <th>path_jpg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>IL_7972535</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>../split/train_dcm/ISIC_2637011.dcm</td>\n      <td>../split/train/mel/2020/ISIC_2637011.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>IL_4649854</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n      <td>../split/train_dcm/ISIC_0015719.dcm</td>\n      <td>../split/train/mel/2020/ISIC_0015719.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>IL_9087444</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>../split/train_dcm/ISIC_0052212.dcm</td>\n      <td>../split/train/mel/2020/ISIC_0052212.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>IL_4255399</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>../split/train_dcm/ISIC_0068279.dcm</td>\n      <td>../split/train/mel/2020/ISIC_0068279.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>IL_6898037</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n      <td>../split/train_dcm/ISIC_0074268.dcm</td>\n      <td>../split/train/mel/2020/ISIC_0074268.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "# Melanoma Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('Melanoma Images', fontsize=16)\n",
    "# for i in range(0, 15):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')\n",
    "    "
   ]
  },
  {
   "source": [
    "<img src=\"../images/melanoma_images.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Non-Melanoma Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = glob('../split/train/not_mel/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('Non-Melanoma Images', fontsize=16)\n",
    "# for i in range(0, 15):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/non_melanoma_images.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# OpenCV Transforms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Grayscale"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../split/train_dcm\"\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16, 6))\n",
    "# plt.suptitle('Grayscale', fontsize=16)\n",
    "# for i in range(0, 10):\n",
    "#     data = pydicom.read_file(os.path.join(path, df.dcm[i]))\n",
    "#     image = data.pixel_array\n",
    "\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "\n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/grayscale.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Gaussian Blur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('Gaussian Blur', fontsize=16)\n",
    "# for i in range(0, 10):\n",
    "#     data = pydicom.read_file(os.path.join(path, df.dcm[i]))\n",
    "#     image = data.pixel_array\n",
    "#     image = cv2.resize(image, (200,200))\n",
    "#     image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), 256/10), -4, 128)\n",
    "\n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/gaussian_blur.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Hue Saturation Brightness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('Hue, Saturation, Brightness', fontsize=16)\n",
    "# for i in range(0, 10):\n",
    "#     data = pydicom.read_file(df['path_dcm'][i])\n",
    "#     image = data.pixel_array\n",
    "    \n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "#     image = cv2.resize(image, (200,200))\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/hue_saturation_brightness.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## LUV Colorspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('LUV Colorspace', fontsize=16)\n",
    "# for i in range(0, 10):\n",
    "#     data = pydicom.read_file(df['path_dcm'][i])\n",
    "#     image = data.pixel_array\n",
    "    \n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "#     image = cv2.resize(image, (200,200))\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/luv_colorspace.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Albumentations Transformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Tranpose"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.Transpose()\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16, 6))\n",
    "# plt.suptitle('Transpose', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256, 256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/transpose.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Vertical Flip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.VerticalFlip()\n",
    "# ])\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16, 6))\n",
    "# plt.suptitle('VerticalFlip', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256, 256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/vertical_flip.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Horizontal FLip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.HorizontalFlip()\n",
    "# ])\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('HorizontalFlip', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/horizontal_flip.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Random Brightness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.RandomBrightness(limit=0.3)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('RandomBrightness', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/random_brightness.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Random Contrast"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.RandomContrast(limit=0.3)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('RandomContrast', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/random_contrast.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## CLAHE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.CLAHE(clip_limit=6.0)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('CLAHE', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/clahe.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Shift Scale Rotate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, border_mode=0)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('ShiftScaleRotate', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/shift_scale_rotate.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cutout"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 128\n",
    "\n",
    "# transform = A.Compose([\n",
    "#     A.Cutout(max_h_size=32, max_w_size=32, num_holes=8)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('Cutout', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/cutout.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Motion Blur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.MotionBlur(blur_limit=5)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('MotionBlur', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/motion_blur.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Median Blur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.MedianBlur(blur_limit=7)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('MedianBlur', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/median_blur.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Gaussian Blur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.GaussianBlur(blur_limit=7)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('GaussianBlur', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/gaussian_blur.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Gauss Noise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.GaussNoise(var_limit=(5.0, 30.0))\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('GaussNoise', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/gauss_noise.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Optical Distortion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.OpticalDistortion(distort_limit=1.0)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('OpticalDistortion', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/optical_distortion.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Grid Distortion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.GridDistortion(num_steps=5, distort_limit=1.)\n",
    "# ])\n",
    "\n",
    "# paths = glob('../split/train/mel/2020/*.jpg')\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "# plt.suptitle('GridDistortion', fontsize=16)\n",
    "# for i in range(0, 10):   \n",
    "#     image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (256,256))\n",
    "#     transformed = transform(image=image)\n",
    "#     aug_image = transformed['image']\n",
    "   \n",
    "#     x = i // 5\n",
    "#     y = i % 5\n",
    "#     axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "#     axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/grid_distortion.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Elastic Transform"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = A.Compose([\n",
    "#     A.ElasticTransform(alpha=3)\n",
    "# ])\n",
    "\n",
    "paths = glob('../split/train/mel/2020/*.jpg')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(16,6))\n",
    "plt.suptitle('ElasticTransform', fontsize=16)\n",
    "for i in range(0, 10):   \n",
    "    image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (256,256))\n",
    "    transformed = transform(image=image)\n",
    "    aug_image = transformed['image']\n",
    "   \n",
    "    x = i // 5\n",
    "    y = i % 5\n",
    "    axes[x, y].imshow(aug_image, cmap=plt.cm.bone)\n",
    "    axes[x, y].axis('off')"
   ]
  },
  {
   "source": [
    "<img src=\"../images/elastic_transform.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/examsherpa/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:2611: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
     ]
    }
   ],
   "source": [
    "transform = A.Compose([\n",
    "    A.Transpose(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightness(limit=0.2, p=0.75),\n",
    "    A.RandomContrast(limit=0.2, p=0.75),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=5),\n",
    "        A.MedianBlur(blur_limit=5),\n",
    "        A.GaussianBlur(blur_limit=5),\n",
    "        A.GaussNoise(var_limit=(5.0, 30.0)),\n",
    "    ], p=0.7),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(distort_limit=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        A.ElasticTransform(alpha=3),\n",
    "    ], p=0.7),\n",
    "    A.CLAHE(clip_limit=4.0, p=0.7),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
    "    A.Resize(256, 256),\n",
    "    A.Cutout(max_h_size=int(256 * 0.375), max_w_size=int(256 * 0.375), num_holes=1, p=0.7),\n",
    "    A.Normalize()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2e452d72ef42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0maug_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/core/composition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_apply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdual_start_end\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdual_start_end\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     )\n\u001b[1;32m     88\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36mapply_with_params\u001b[0;34m(self, params, force_apply, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mtarget_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_target_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mtarget_dependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dependence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtarget_dependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/augmentations/transforms.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, image, hue_shift, sat_shift, val_shift, **params)\u001b[0m\n\u001b[1;32m   2232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msat_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_shift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_hsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msat_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/augmentations/functional.py\u001b[0m in \u001b[0;36mwrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/augmentations/functional.py\u001b[0m in \u001b[0;36mshift_hsv\u001b[0;34m(img, hue_shift, sat_shift, val_shift)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shift_hsv_uint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msat_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shift_hsv_non_uint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msat_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nn-env/lib/python3.6/site-packages/albumentations/augmentations/functional.py\u001b[0m in \u001b[0;36m_shift_hsv_uint8\u001b[0;34m(img, hue_shift, sat_shift, val_shift)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhue_shift\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paths = glob('../split/train/mel/2020/*.jpg')\n",
    "\n",
    "for i in range(0, 467):   \n",
    "    f, ax = plt.subplots()\n",
    "    image = cv2.imread(paths[i], cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transformed = transform(image=image)\n",
    "    aug_image = transformed['image']\n",
    "    plt.imshow(aug_image)\n",
    "    plt.savefig(\"../split/train/mel/2020_T/aug_image_{}.png\".format(i))"
   ]
  },
  {
   "source": [
    "# PyTorch Transforms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hair_remove(image):\n",
    "    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(1,(17,17))\n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "    _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n",
    "    final_image = cv2.inpaint(image,threshold,1,cv2.INPAINT_TELEA)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hairy_ = df[df[\"sex\"] == 1].reset_index().iloc[[12, 14, 17, 22, 33, 34]]\n",
    "image_list = hairy['path_jpg']\n",
    "image_list = image_list.reset_index()['path_jpg']"
   ]
  }
 ]
}