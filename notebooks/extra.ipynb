{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['file'] = train.image_name.apply(lambda x: str(x) + \".jpg\")\n",
    "test['file'] = test.image_name.apply(lambda x: str(x) + \".jpg\")\n",
    "train.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train.file\n",
    "test_ids = test.file\n",
    "train.head()\n",
    "train.to_csv(\"data/train.csv\")\n",
    "test.to_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpeg_dir = 'images/jpeg'\n",
    "dicom_dir = 'images/dicom'\n",
    "jpeg_list = [file for file in os.listdir(jpeg_dir) if file.endswith('.jpg')]\n",
    "dicom_list = [file for file in os.listdir(dicom_dir) if file.endswith('.dcm')]\n",
    "train_ids = train.file\n",
    "test_ids = test.file\n",
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "with open('data/train.csv', newline='') as csvfile:\n",
    "    linereader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in linereader:\n",
    "        name = row[0]\n",
    "        try:\n",
    "            os.('images/jpeg/' + name, 'images/jpeg/train/' + name)\n",
    "            print(name + \" moved to new folder.\")\n",
    "        except FileNotFoundError:\n",
    "            pass \n",
    "        except FileExistsError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def main():\n",
    "    csv_file = \"data/train.csv\"\n",
    "    from_folder = \"images/jpeg/\"\n",
    "    to_folder = \"images/jpeg/train/\"\n",
    "\n",
    "    with open(csv_file, 'r', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            file_name = row[0]\n",
    "            from_filename = os.path.join(from_folder, file_name)\n",
    "            to_filename = os.path.join(to_folder, file_name)\n",
    "\n",
    "            try:\n",
    "                shutil.move(from_filename, to_filename)\n",
    "                print(\"Moved - '{}' -> '{}'\".format(from_filename, to_filename))\n",
    "            except shutil.Error as e:\n",
    "                print(\"Failed - '{}' -> '{}'\".format(from_filename, to_filename))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(jpeg_dir, output=\"output\", seed=42, ratio=(.8,0.1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers, optimizers\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "# Converting DICOM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import PIL # optional\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# make it True if you want in PNG format\n",
    "PNG = True\n",
    "# Specify the .dcm folder path\n",
    "folder_path = \"images/test\"\n",
    "# Specify the .jpg/.png folder path\n",
    "jpg_folder_path = \"images/png_test\"\n",
    "images_path = os.listdir(folder_path)\n",
    "for n, image in enumerate(images_path):\n",
    "    ds = dicom.dcmread(os.path.join(folder_path, image))\n",
    "    pixel_array_numpy = ds.pixel_array\n",
    "    if PNG == False:\n",
    "        image = image.replace('.dcm', '.jpg')\n",
    "    else:\n",
    "        image = image.replace('.dcm', '.png')\n",
    "    cv2.imwrite(os.path.join(jpg_folder_path, image), pixel_array_numpy)\n",
    "    if n % 50 == 0:\n",
    "        print('{} image converted'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"images/jpeg\"\n",
    "train_path = \"images/jpeg/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it True if you want in PNG format\n",
    "PNG = True\n",
    "# Specify the .dcm folder path\n",
    "folder_path = \"images/train\"\n",
    "# Specify the .jpg/.png folder path\n",
    "jpg_folder_path = \"images/png_train\"\n",
    "images_path = os.listdir(folder_path)\n",
    "for n, image in enumerate(images_path):\n",
    "    ds = dicom.dcmread(os.path.join(folder_path, image))\n",
    "    pixel_array_numpy = ds.pixel_array\n",
    "    if PNG == False:\n",
    "        image = image.replace('.dcm', '.jpg')\n",
    "    else:\n",
    "        image = image.replace('.dcm', '.png')\n",
    "    cv2.imwrite(os.path.join(jpg_folder_path, image), pixel_array_numpy)\n",
    "    if n % 50 == 0:\n",
    "        print('{} image converted'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your image path\n",
    "image_path = 'xray.dcm'\n",
    "ds = dicom.dcmread(image_path)\n",
    "plt.imshow( ds.pixel_array)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df['target'] = df['target'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255.,validation_split=0.20)\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=\"images/jpeg\",\n",
    "    x_col=\"file\",\n",
    "    y_col=\"target\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    target_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automation.py\n",
    "import os\n",
    "from shutil import move\n",
    "\n",
    "# directory path\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/Melanoma/test'\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/Melanoma/train'\n",
    "test_zero = '/content/drive/MyDrive/Colab Notebooks/Melanoma/test/zero'\n",
    "test_one = '/content/drive/MyDrive/Colab Notebooks/Melanoma/test/one'\n",
    "\n",
    "# category wise file types\n",
    "doc_types = ('.doc', '.docx', '.txt', '.pdf', '.xls', '.ppt', '.xlsx', '.pptx')\n",
    "img_types = ('.jpg', '.jpeg', '.png', '.svg', '.gif', '.tif', '.tiff')\n",
    "software_types = ('.exe', '.pkg', '.dmg')\n",
    "\n",
    "def get_non_hidden_files_except_current_file(root_dir):\n",
    "  return [f for f in os.listdir(root_dir) if os.path.isfile(f) and not f.startswith('.') and not f.__eq__(__file__)]\n",
    "\n",
    "def move_files(files):\n",
    "  for file in files:\n",
    "    # file moved and overwritten if already exists\n",
    "    if file in melanoma_ids:\n",
    "      move(file, '{}/{}'.format(one, file))\n",
    "      print('file {} moved to {}'.format(file, one))\n",
    "    elif file in non_melanoma_ids:\n",
    "      move(file, '{}/{}'.format(zero, file))\n",
    "      print('file {} moved to {}'.format(file, zero))\n",
    "    elif file.endswith(\".jpg\"):\n",
    " b \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "files = get_non_hidden_files_except_current_file(root_dir)\n",
    "move_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.20)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory = \"./images/train_jpg\",\n",
    "    x_col = \"jpg\",\n",
    "    y_col = \"target\",\n",
    "    subset = \"training\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory = \"./images/train_jpg\",\n",
    "    x_col = \"jpg\",\n",
    "    y_col = \"target\",\n",
    "    subset = \"validation\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory=\"./images/test/\",\n",
    "    x_col = \"jpg\",\n",
    "    y_col = 'target',\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizers.RMSprop(lr=0.0001, decay=1e-6), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN  =train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator = train_generator,\n",
    "                    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                    validation_data = valid_generator,\n",
    "                    validation_steps = STEP_SIZE_VALID,\n",
    "                    epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler \n",
    "import albumentations as A\n",
    "import geffnet"
   ]
  }
 ]
}