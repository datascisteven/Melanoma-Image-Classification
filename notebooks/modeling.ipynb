{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('nn-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6555959b910bb7a8fb6f47a2dcc8365b919d4ffbc6f566ad680344e31443b77e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importing Packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pydicom as dicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import os, sys, time, shutil, scipy, cv2, json, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ignoring warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler \n",
    "import albumentations as A\n",
    "import geffnet\n",
    "\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, r2_score, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "\n",
    "# Build a baseline fully connected model\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "source": [
    "# Baseline Model:  Densely Connected Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           file  patient_id   lesion_id  gender   age             site  \\\n",
       "0  ISIC_2637011  IP_7279968  IL_7972535    male  45.0        head/neck   \n",
       "1  ISIC_0015719  IP_3075186  IL_4649854  female  45.0  upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  IL_9087444  female  50.0  lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  IL_4255399  female  45.0        head/neck   \n",
       "4  ISIC_0074268  IP_8723313  IL_6898037  female  55.0  upper extremity   \n",
       "\n",
       "  diagnosis ben_mal  target               jpg  \n",
       "0   unknown  benign       0  ISIC_2637011.jpg  \n",
       "1   unknown  benign       0  ISIC_0015719.jpg  \n",
       "2     nevus  benign       0  ISIC_0052212.jpg  \n",
       "3   unknown  benign       0  ISIC_0068279.jpg  \n",
       "4   unknown  benign       0  ISIC_0074268.jpg  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>patient_id</th>\n      <th>lesion_id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>site</th>\n      <th>diagnosis</th>\n      <th>ben_mal</th>\n      <th>target</th>\n      <th>jpg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>IL_7972535</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_2637011.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>IL_4649854</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0015719.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>IL_9087444</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0052212.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>IL_4255399</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0068279.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>IL_6898037</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0074268.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train_df.csv', index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           file   age             site lesion_id  gender  target  \\\n",
       "0  ISIC_0000000  55.0   anterior torso       NaN  female       0   \n",
       "1  ISIC_0000001  30.0   anterior torso       NaN  female       0   \n",
       "2  ISIC_0000002  60.0  upper extremity       NaN  female       1   \n",
       "3  ISIC_0000003  30.0  upper extremity       NaN    male       0   \n",
       "4  ISIC_0000004  80.0  posterior torso       NaN    male       1   \n",
       "\n",
       "                jpg  \n",
       "0  ISIC_0000000.jpg  \n",
       "1  ISIC_0000001.jpg  \n",
       "2  ISIC_0000002.jpg  \n",
       "3  ISIC_0000003.jpg  \n",
       "4  ISIC_0000004.jpg  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>age</th>\n      <th>site</th>\n      <th>lesion_id</th>\n      <th>gender</th>\n      <th>target</th>\n      <th>jpg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000000</td>\n      <td>55.0</td>\n      <td>anterior torso</td>\n      <td>NaN</td>\n      <td>female</td>\n      <td>0</td>\n      <td>ISIC_0000000.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000001</td>\n      <td>30.0</td>\n      <td>anterior torso</td>\n      <td>NaN</td>\n      <td>female</td>\n      <td>0</td>\n      <td>ISIC_0000001.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000002</td>\n      <td>60.0</td>\n      <td>upper extremity</td>\n      <td>NaN</td>\n      <td>female</td>\n      <td>1</td>\n      <td>ISIC_0000002.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000003</td>\n      <td>30.0</td>\n      <td>upper extremity</td>\n      <td>NaN</td>\n      <td>male</td>\n      <td>0</td>\n      <td>ISIC_0000003.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000004</td>\n      <td>80.0</td>\n      <td>posterior torso</td>\n      <td>NaN</td>\n      <td>male</td>\n      <td>1</td>\n      <td>ISIC_0000004.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "test = pd.read_csv('../data/test_df.csv', index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ISIC_2019_Training_GroundTruth.csv',\n",
       " 'ISIC_2019_Training_Metadata.csv',\n",
       " 'ISIC_2020_Training_Duplicates.csv',\n",
       " 'ISIC_2020_Training_GroundTruth_v2.csv',\n",
       " 'test.csv',\n",
       " 'test_df.csv',\n",
       " 'train.csv',\n",
       " 'train_df.csv',\n",
       " 'val.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "WORK_DIR = \"../data\"\n",
    "label_col = \"target\"\n",
    "img_col = \"jpg\"\n",
    "train_folder = \"../images/train\"\n",
    "test_folder = \"../images/test\"\n",
    "\n",
    "os.listdir(WORK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "           file  patient_id   lesion_id  gender   age             site  \\\n0  ISIC_2637011  IP_7279968  IL_7972535    male  45.0        head/neck   \n1  ISIC_0015719  IP_3075186  IL_4649854  female  45.0  upper extremity   \n2  ISIC_0052212  IP_2842074  IL_9087444  female  50.0  lower extremity   \n3  ISIC_0068279  IP_6890425  IL_4255399  female  45.0        head/neck   \n4  ISIC_0074268  IP_8723313  IL_6898037  female  55.0  upper extremity   \n\n  diagnosis ben_mal  target               jpg  label_name  \n0   unknown  benign       0  ISIC_2637011.jpg           0  \n1   unknown  benign       0  ISIC_0015719.jpg           0  \n2     nevus  benign       0  ISIC_0052212.jpg           0  \n3   unknown  benign       0  ISIC_0068279.jpg           0  \n4   unknown  benign       0  ISIC_0074268.jpg           0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>patient_id</th>\n      <th>lesion_id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>site</th>\n      <th>diagnosis</th>\n      <th>ben_mal</th>\n      <th>target</th>\n      <th>jpg</th>\n      <th>label_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>IL_7972535</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_2637011.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>IL_4649854</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0015719.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>IL_9087444</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0052212.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>IL_4255399</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0068279.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>IL_6898037</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n      <td>ISIC_0074268.jpg</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train_df.csv\"), index_col=0)\n",
    "label_names = train_labels[label_col].value_counts().index\n",
    "label_map = {name:i for (i,name) in enumerate(label_names)}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "train_labels['label_name'] = train_labels[label_col].copy()\n",
    "train_labels[label_col] = train_labels[label_col].map(label_map)\n",
    "display(train_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           file   age             site lesion_id  gender  target  \\\n",
       "0  ISIC_0000000  55.0   anterior torso       NaN  female       0   \n",
       "1  ISIC_0000001  30.0   anterior torso       NaN  female       0   \n",
       "2  ISIC_0000002  60.0  upper extremity       NaN  female       1   \n",
       "3  ISIC_0000003  30.0  upper extremity       NaN    male       0   \n",
       "4  ISIC_0000004  80.0  posterior torso       NaN    male       1   \n",
       "\n",
       "                jpg  \n",
       "0  ISIC_0000000.jpg  \n",
       "1  ISIC_0000001.jpg  \n",
       "2  ISIC_0000002.jpg  \n",
       "3  ISIC_0000003.jpg  \n",
       "4  ISIC_0000004.jpg  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>age</th>\n      <th>site</th>\n      <th>lesion_id</th>\n      <th>gender</th>\n      <th>target</th>\n      <th>jpg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000000</td>\n      <td>55.0</td>\n      <td>anterior torso</td>\n      <td>NaN</td>\n      <td>female</td>\n      <td>0</td>\n      <td>ISIC_0000000.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000001</td>\n      <td>30.0</td>\n      <td>anterior torso</td>\n      <td>NaN</td>\n      <td>female</td>\n      <td>0</td>\n      <td>ISIC_0000001.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000002</td>\n      <td>60.0</td>\n      <td>upper extremity</td>\n      <td>NaN</td>\n      <td>female</td>\n      <td>1</td>\n      <td>ISIC_0000002.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000003</td>\n      <td>30.0</td>\n      <td>upper extremity</td>\n      <td>NaN</td>\n      <td>male</td>\n      <td>0</td>\n      <td>ISIC_0000003.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000004</td>\n      <td>80.0</td>\n      <td>posterior torso</td>\n      <td>NaN</td>\n      <td>male</td>\n      <td>1</td>\n      <td>ISIC_0000004.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "BATCH_SIZE = 8\n",
    "STEPS_PER_EPOCH = len(train_labels)*0.8 / BATCH_SIZE\n",
    "VALIDATION_STEPS = len(train_labels)*0.2 / BATCH_SIZE\n",
    "EPOCHS = 4\n",
    "TARGET_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.target = train.target.astype(str)\n",
    "test.target = test.target.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 26501 validated image filenames belonging to 2 classes.\n",
      "Found 6625 validated image filenames belonging to 2 classes.\n",
      "Found 25331 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.20)\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory = \"./images/train_jpg\",\n",
    "    x_col = \"jpg\",\n",
    "    y_col = \"target\",\n",
    "    subset = \"training\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (256,256))\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory = \"./images/train_jpg\",\n",
    "    x_col = \"jpg\",\n",
    "    y_col = \"target\",\n",
    "    subset = \"validation\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (256,256))\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test,\n",
    "    directory=\"./images/test/\",\n",
    "    x_col = \"jpg\",\n",
    "    y_col = 'target',\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training samples: 32\nNumber of testing samples: 32\nNumber of validation samples: 32\ntrain_images shape: (32, 256, 256, 3)\ntrain_labels shape: (32, 2)\ntest_images shape: (32, 256, 256, 3)\ntest_labels shape: (32, 2)\nval_images shape: (32, 256, 256, 3)\nval_labels shape: (32, 2)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 196608)\n(32, 196608)\n(32, 196608)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (32,1))\n",
    "test_y = np.reshape(test_labels[:,0], (32,1))\n",
    "val_y = np.reshape(val_labels[:,0], (32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(196608,))) # 2 hidden layers\n",
    "model.add(layers.Dense(7, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6604 - accuracy: 0.9688 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1894 - accuracy: 0.9688 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1219 - accuracy: 0.9688 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1194 - accuracy: 0.9688 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1254 - accuracy: 0.9688 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1243 - accuracy: 0.9688 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1254 - accuracy: 0.9688 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1168 - accuracy: 0.9688 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1120 - accuracy: 0.9688 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1206 - accuracy: 0.9688 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1056 - accuracy: 0.9688 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1166 - accuracy: 0.9688 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1125 - accuracy: 0.9688 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1133 - accuracy: 0.9688 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1048 - accuracy: 0.9688 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0967 - accuracy: 0.9688 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0949 - accuracy: 0.9688 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1012 - accuracy: 0.9688 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1251 - accuracy: 0.9688 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1008 - accuracy: 0.9688 - val_loss: 2.2155e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2870 - accuracy: 0.9688 - val_loss: 4.5184e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1822 - accuracy: 0.9688 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0970 - accuracy: 0.9688 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0911 - accuracy: 0.9688 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1076 - accuracy: 0.9688 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0819 - accuracy: 0.9688 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0957 - accuracy: 0.9688 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0817 - accuracy: 0.9688 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0926 - accuracy: 0.9688 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0784 - accuracy: 0.9688 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1003 - accuracy: 0.9688 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0752 - accuracy: 0.9688 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1060 - accuracy: 0.9688 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0673 - accuracy: 0.9688 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0659 - accuracy: 0.9688 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0707 - accuracy: 0.9688 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.0794 - accuracy: 0.9688 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0732 - accuracy: 0.9688 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1136 - accuracy: 0.9688 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0583 - accuracy: 0.9688 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0634 - accuracy: 0.9688 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0638 - accuracy: 0.9688 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0823 - accuracy: 0.9688 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0659 - accuracy: 0.9688 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0778 - accuracy: 0.9688 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0631 - accuracy: 0.9688 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0721 - accuracy: 0.9688 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0592 - accuracy: 0.9688 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0843 - accuracy: 0.9688 - val_loss: 0.0329 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_img, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0551 - accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1338 - accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_img, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.05513884872198105, 0.96875]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.1337727308273315, 0.78125]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 20)                3932180   \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 147       \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 40        \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 6         \n=================================================================\nTotal params: 3,932,373\nTrainable params: 3,932,373\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "source": [
    "# Build a CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7315 - acc: 0.0312 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.9688 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.9688 - val_loss: 0.0246 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1301 - acc: 0.9688 - val_loss: 0.0270 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1291 - acc: 0.9688 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1286 - acc: 0.9688 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.9688 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.9688 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.9688 - val_loss: 0.0326 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1277 - acc: 0.9688 - val_loss: 0.0327 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.9688 - val_loss: 0.0329 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.9688 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.9688 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.9688 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1270 - acc: 0.9688 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.9688 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.9688 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.9688 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.9688 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.9688 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.9688 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.9688 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.9688 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.9688 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1256 - acc: 0.9688 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.9688 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.9688 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.9688 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.9688 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.9688 - val_loss: 0.0327 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 332ms/step - loss: 0.1249 - acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 1s 541ms/step - loss: 0.8336 - acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.12485035508871078, 0.96875]"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.8335974216461182, 0.75]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}